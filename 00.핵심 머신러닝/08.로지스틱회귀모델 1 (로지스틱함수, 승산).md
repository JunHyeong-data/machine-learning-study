# 로지스틱 회귀 모델 (Logistic Regression)

## 1. 강의 개요

로지스틱 회귀 모델에 대한 강의는 크게 다음 두 부분으로 구성된다.

1. **로지스틱 회귀 모델의 이론적 배경과 모델 형태**
2. **모델 파라미터 추정 및 결과 해석 (다음 강의)**

이번 강의에서는  
**로지스틱 회귀 모델이 왜 필요한지**,  
그리고 **모델이 어떤 수학적 형태를 가지는지**를 중심으로 설명한다.

---

## 2. 선형 회귀 모델의 한계

기존에 배운 **선형 회귀 모델**은 출력 변수가 연속형일 때 사용된다.

- 입력 변수 $x$: 설명 변수 (예: 나이)
- 출력 변수 $y$: 연속형 변수 (예: 혈압)

선형 회귀 모델은 다음과 같이 표현된다.

$$y = \beta_0 + \beta_1 x + \varepsilon$$

이때,
- $\beta_0$: 절편
- $\beta_1$: $x$가 1 증가할 때 $y$의 평균 변화량

그러나 출력 변수 $y$가 **범주형 변수**인 경우에는 선형 회귀 모델을 그대로 적용할 수 없다.

### 범주형 데이터에서의 문제점
- 출력 변수가 0 또는 1만 가지므로 정규성 가정이 성립하지 않음
- 등분산성 가정이 위배됨
- 최소제곱법(OLS)을 통한 추정이 타당하지 않음

따라서 **범주형 출력 변수를 위한 새로운 모델**이 필요하다.

---

## 3. 분류 문제와 로지스틱 회귀

출력 변수가 범주형인 문제를 **분류 문제(classification)**라고 한다.

### 대표적인 분류 문제 예시
- 불량품 / 양품
- 질병 있음 / 없음
- 고객 이탈 / 유지
- 스팸 메일 / 정상 메일

이러한 분류 문제를 해결하기 위해 사용되는 대표적인 모델이  
**로지스틱 회귀 모델(Logistic Regression)**이다.

---

## 4. 이진 확률 변수와 기대값

<img width="1016" height="892" alt="image" src="https://github.com/user-attachments/assets/a4074b8a-9cd9-48cb-aee5-c1cd826c9b9a" />

출력 변수 $y$가 다음과 같은 값을 가진다고 하자.

$$y \in \{0, 1\}$$

이는 **베르누이 확률 변수(Bernoulli random variable)**이다.

- $P(y = 1) = \pi$
- $P(y = 0) = 1 - \pi$

### 기대값

베르누이 확률 변수의 기대값은 다음과 같다.

$$E[y] = 1 \cdot \pi + 0 \cdot (1 - \pi) = \pi$$

즉,

> **이진 확률 변수의 기대값은 사건이 발생할 확률과 같다.**

따라서 로지스틱 회귀 모델은  
**입력 변수 $x$가 주어졌을 때 $y = 1$이 될 확률을 직접 모델링**하는 모델이다.

---

## 5. 로지스틱 함수 (Sigmoid Function)

<img width="1356" height="909" alt="image" src="https://github.com/user-attachments/assets/94ab23a3-39ab-4560-999b-f0f83ec91b25" />

확률은 반드시 **0과 1 사이의 값**을 가져야 한다.  
이를 만족시키는 대표적인 함수가 **로지스틱 함수(시그모이드 함수)**이다.

$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

### 로지스틱 함수의 특징
- 입력값: $z \in (-\infty, \infty)$
- 출력값: $\sigma(z) \in (0, 1)$
- S자 형태(S-curve)
- 단조 증가 함수

이 함수는 실수 전체를 입력으로 받아 확률 값으로 변환해 준다.

---

## 6. 단순 로지스틱 회귀 모델

입력 변수가 하나일 때의 로지스틱 회귀 모델은 다음과 같이 정의된다.

$$\pi(x) = P(y = 1 \mid x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}}$$

여기서,
- $\beta_0$: 절편
- $\beta_1$: 회귀 계수
- 출력값 $\pi(x)$: 확률

이 모델은 **비선형 함수 형태**이므로  
$\beta_1$의 해석이 선형 회귀 모델처럼 직관적이지 않다.

---

## 7. 오즈(Odds)의 개념

### 오즈의 정의

<img width="1131" height="540" alt="image" src="https://github.com/user-attachments/assets/54752285-e0c9-4f20-9ad9-01c545d0107d" />

사건 $y = 1$이 발생할 확률을 $\pi$라고 할 때,  
오즈(Odds)는 **사건이 발생할 확률과 발생하지 않을 확률의 비율**로 정의된다.

$$\text{Odds} = \frac{\pi}{1 - \pi}$$

---

### 확률에 따른 오즈의 극한 거동

확률 $\pi \in (0,1)$에 대해 오즈는 다음과 같은 성질을 가진다.

- 사건이 발생할 확률이 1에 가까워질수록,
  $$\pi \to 1 \quad \Rightarrow \quad \text{Odds} \to \infty$$

- 사건이 발생할 확률이 0에 가까워질수록,
  $$\pi \to 0 \quad \Rightarrow \quad \text{Odds} \to 0$$

즉, 오즈는 확률을 **비율 관점에서 표현한 값**이며  
확률이 극단적인 값에 가까워질수록 매우 큰 값 또는 매우 작은 값을 갖는다.

---

## 8. 로그 오즈 (Log-Odds, Logit)

<img width="1412" height="1046" alt="image" src="https://github.com/user-attachments/assets/94ec4220-03a1-49fb-bbbe-d91fae33bbdc" />

오즈에 로그를 취한 값을 **로그 오즈(Log-Odds)** 또는 **로짓(Logit)**이라고 한다.

$$\text{Log-Odds} = \log\left(\frac{\pi}{1 - \pi}\right)$$

로그 오즈는 확률 값을 실수 전체 범위로 변환해 준다.

---

## 9. 로지스틱 회귀의 핵심 아이디어

로지스틱 회귀 모델에서 로그 오즈는 입력 변수의 **선형 결합**으로 표현된다.

$$\log\left(\frac{\pi(x)}{1 - \pi(x)}\right) = \beta_0 + \beta_1 x$$

즉,
- 확률 자체는 비선형
- **로그 오즈는 선형 구조**

이것이 로지스틱 회귀 모델의 핵심 아이디어이다.

---

## 10. 파라미터 해석

### 회귀 계수 $\beta_1$의 의미

- $x$가 1 증가할 때
- **로그 오즈가 $\beta_1$만큼 증가**

이를 지수화하면,

$$e^{\beta_1}$$

는 **오즈의 변화 배율**을 의미한다.

---

## 11. 확률, 오즈, 로그 오즈의 관계

- $\pi = 0.5$
  $$\text{Odds} = 1, \quad \text{Log-Odds} = 0$$

- $\pi \to 1$
  $$\text{Log-Odds} \to +\infty$$

- $\pi \to 0$
  $$\text{Log-Odds} \to -\infty$$

---

## 12. 강의 정리

- 선형 회귀는 연속형 출력 변수에 적합
- 범주형 출력 변수에는 로지스틱 회귀 사용
- 로지스틱 함수로 확률을 모델링
- 로그 오즈 변환을 통해 선형 구조 확보
- 다음 강의: **최대우도추정(MLE)을 통한 파라미터 추정과 결과 해석**
