# 머신 러닝 모델 학습 프로세스

## 1. 개요

지난 예측 모델링 강의에서는 모델링에 대한 개요와 예제 중심의 설명을 다뤘다.  
이번 강의에서는 **예측 모델을 포함한 머신 러닝 모델을 실제로 어떻게 구축하는지**를 보다 자세히 설명한다.

머신 러닝 모델링의 핵심은  
👉 **입력 변수(X)와 출력 변수(Y) 사이의 관계를 학습하는 것**이다.

---

## 2. 데이터의 기본 구조

- 데이터는 일반적으로 행(row)에 관측치, 열(column)에 변수가 위치
- 변수는 크게 두 가지로 구분됨
  - **X (독립 변수)**: 원인이 되는 변수
  - **Y (종속 변수)**: 결과가 되는 변수

핵심 가정:
> X와 Y 사이에는 **원인–결과 관계**가 존재한다.

---

## 3. 예측 모델링의 실제 사례

머신 러닝 모델링은 다양한 현실 문제를 X–Y 관계로 표현할 수 있다.

### 대표적인 예시
- 고객 이탈 예측 (통신사, 카드사, 백화점)
- 장비 고장 예측 (제조업)
- 수요 예측 (다음 분기 / 내년도 판매량)
- 금융 투자 전략 예측
- 보험 사기 탐지
- SNS·텍스트 데이터를 활용한 시장 반응 예측

👉 결국 **관심 대상은 Y**, 이를 설명하는 수단이 X

---

## 4. X와 Y의 관계: 함수로 표현

<img width="800" alt="image" src="https://github.com/user-attachments/assets/778d1a96-566c-4f86-b5c1-276e12849654" />

### 핵심 아이디어
- 여러 개의 X를 **어떻게 조합해서 Y를 표현할 것인가**
- 이를 수학적으로 표현하면:

```

Y = f(X)

```

- 여기서 `f`가 바로 **모델(Model)**

---

## 5. 단순한 예제를 통한 이해

### 예제 1: 단일 변수
- X = 10 → Y = 30  
→ `Y = X + 20`

### 예제 2: 선형 관계
| X | Y |
|---|---|
| 0 | 0 |
| 1 | 2 |
| 2 | 4 |
| 3 | 6 |

→ `Y = 2X`

### 예제 3: 절편 포함
| X | Y |
|---|---|
| 1 | 4 |
| 2 | 6 |
| 3 | 8 |

→ `Y = 2X + 2`

---

## 6. 다변량 입력 변수

### 두 개의 입력 변수
| X1 | X2 | Y |
|----|----|---|
| 1  | 2  | 3 |
| 2  | 3  | 5 |

→ `Y = X1 + X2`

### 가중치가 다른 경우
| X1 | X2 | Y |
|----|----|----|
| 1  | 2  | 9.5 |
| 2  | 3  | 13 |

→ `Y = 2X1 + 3X2`

---

## 7. 현실 데이터와 오차(Error)

현실에서는 X만으로 Y를 **완벽히 설명할 수 없다**.

### 예시: 중고차 가격
- 입력 변수: 주행거리, 마력, 배기량
- 출력 변수: 가격

👉 설명 가능한 부분 + 설명 불가능한 부분 존재

```

Y = f(X) + ε

```

- `ε (epsilon)`: 오차(Error)

---

## 8. 파라미터(Parameter)

<img width="800" alt="image" src="https://github.com/user-attachments/assets/555bf743-63e4-4521-a0fe-62bf701bc604" />

모델은 보통 다음과 같이 표현된다.

```

Y = w1X1 + w2X2 + ε

```

- `w1`, `w2` → **파라미터(Parameter)**
- 의미:
  - X가 Y에 얼마나 영향을 미치는지 나타내는 핵심 값
  - 한국어로는 **모수**, **매개변수**

---

## 9. 손실 함수(Loss Function)

<img width="800" alt="image" src="https://github.com/user-attachments/assets/fe6c793c-e51d-4662-afbd-a961bc520b8c" />

### 개별 오차
```

Error = Y - f(X)

```

### 손실 함수
- 오차의 제곱을 사용
- 이유: 음수/양수 상쇄 방지

```

Loss = (Y - f(X))²

```

---

## 10. 비용 함수(Cost Function)

<img width="800" alt="image" src="https://github.com/user-attachments/assets/28fe113f-7edb-43a8-bf54-b93b1abd0ac7" />

- 전체 데이터에 대한 손실을 합산 (또는 평균)

```

Cost = Σ (Yi - f(Xi))²

```

- 목표:
> **비용 함수를 최소화하는 파라미터를 찾는 것**

---

## 11. 최적화 문제로 표현

```

minimize_w  Σ (Yi - f(Xi))²

```

- 최적의 파라미터는 `^`(hat)을 씌워 표현

```

ŵ1, ŵ2

```

---

## 12. 모델의 종류

<img width="800" alt="image" src="https://github.com/user-attachments/assets/c53a4114-4769-46f9-8225-bf227727adfb" />

| 모델 | 특징 |
|-----|-----|
| 다중 선형 회귀 | X의 선형 결합 |
| 로지스틱 회귀 | 확률 예측 |
| 의사결정나무 | 규칙 기반 분기 |
| 인공신경망 | 비선형 복잡 모델 |

---

## 13. 파라미터 추정 알고리즘

<img width="800" alt="image" src="https://github.com/user-attachments/assets/1e1600ec-c23f-4f2e-aba1-de944bd7e6f9" />

| 모델 | 알고리즘 |
|----|----|
| 선형 회귀 | Least Squares Estimation |
| 로지스틱 회귀 | Gradient Descent |
| 신경망 | Backpropagation |

---

## 14. 머신 러닝 모델 학습의 두 단계

<img width="800" alt="image" src="https://github.com/user-attachments/assets/e24e5375-e8f0-4168-993b-f185b239c777" />

### 1️⃣ 모델 결정
- X를 어떻게 조합해서 Y를 표현할지 결정
- 즉, **모델 구조(Structure)** 선택

### 2️⃣ 파라미터 추정
- 비용 함수를 최소화하는 파라미터 탐색
- **학습(Learning)의 핵심**

---

## 15. 정리

- 머신 러닝 모델 학습이란:
  1. **모델 구조를 정하고**
  2. **데이터를 이용해 파라미터를 학습하는 과정**
- 실제 데이터와 모델 예측값의 차이를 최소화하는 것이 목표
- 이 과정을 통해 최종 머신 러닝 모델이 완성된다

---
